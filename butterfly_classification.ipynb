{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qzml-eiudI5l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import math\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MOGcucPIdI5p"
      },
      "outputs": [],
      "source": [
        "original_dataset_dir = './dataset'\n",
        "classes_list = os.listdir(original_dataset_dir)\n",
        "\n",
        "base_dir = './splitted'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list:\n",
        "    os.mkdir(os.path.join(train_dir, cls))\n",
        "    os.mkdir(os.path.join(validation_dir, cls))\n",
        "    os.mkdir(os.path.join(test_dir, cls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQPgyWvkdI5p",
        "outputId": "a47dff8c-1407-4698-a88a-4d6a397a7b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size( ADONIS ):  52\n",
            "Validation size( ADONIS ):  17\n",
            "Test size( ADONIS ):  17\n",
            "Train size( AFRICAN GIANT SWALLOWTAIL ):  45\n",
            "Validation size( AFRICAN GIANT SWALLOWTAIL ):  15\n",
            "Test size( AFRICAN GIANT SWALLOWTAIL ):  15\n",
            "Train size( AMERICAN SNOOT ):  44\n",
            "Validation size( AMERICAN SNOOT ):  14\n",
            "Test size( AMERICAN SNOOT ):  14\n",
            "Train size( AN 88 ):  51\n",
            "Validation size( AN 88 ):  17\n",
            "Test size( AN 88 ):  17\n",
            "Train size( APPOLLO ):  54\n",
            "Validation size( APPOLLO ):  18\n",
            "Test size( APPOLLO ):  18\n",
            "Train size( ATALA ):  60\n",
            "Validation size( ATALA ):  20\n",
            "Test size( ATALA ):  20\n",
            "Train size( BANDED ORANGE HELICONIAN ):  58\n",
            "Validation size( BANDED ORANGE HELICONIAN ):  19\n",
            "Test size( BANDED ORANGE HELICONIAN ):  19\n",
            "Train size( BANDED PEACOCK ):  49\n",
            "Validation size( BANDED PEACOCK ):  16\n",
            "Test size( BANDED PEACOCK ):  16\n",
            "Train size( BECKERS WHITE ):  48\n",
            "Validation size( BECKERS WHITE ):  16\n",
            "Test size( BECKERS WHITE ):  16\n",
            "Train size( BLACK HAIRSTREAK ):  51\n",
            "Validation size( BLACK HAIRSTREAK ):  17\n",
            "Test size( BLACK HAIRSTREAK ):  17\n",
            "Train size( BLUE MORPHO ):  45\n",
            "Validation size( BLUE MORPHO ):  15\n",
            "Test size( BLUE MORPHO ):  15\n",
            "Train size( BLUE SPOTTED CROW ):  51\n",
            "Validation size( BLUE SPOTTED CROW ):  17\n",
            "Test size( BLUE SPOTTED CROW ):  17\n",
            "Train size( BROWN SIPROETA ):  59\n",
            "Validation size( BROWN SIPROETA ):  19\n",
            "Test size( BROWN SIPROETA ):  19\n",
            "Train size( CABBAGE WHITE ):  54\n",
            "Validation size( CABBAGE WHITE ):  18\n",
            "Test size( CABBAGE WHITE ):  18\n",
            "Train size( CAIRNS BIRDWING ):  49\n",
            "Validation size( CAIRNS BIRDWING ):  16\n",
            "Test size( CAIRNS BIRDWING ):  16\n",
            "Train size( CHECQUERED SKIPPER ):  57\n",
            "Validation size( CHECQUERED SKIPPER ):  19\n",
            "Test size( CHECQUERED SKIPPER ):  19\n",
            "Train size( CHESTNUT ):  51\n",
            "Validation size( CHESTNUT ):  17\n",
            "Test size( CHESTNUT ):  17\n",
            "Train size( CLEOPATRA ):  55\n",
            "Validation size( CLEOPATRA ):  18\n",
            "Test size( CLEOPATRA ):  18\n",
            "Train size( CLODIUS PARNASSIAN ):  52\n",
            "Validation size( CLODIUS PARNASSIAN ):  17\n",
            "Test size( CLODIUS PARNASSIAN ):  17\n",
            "Train size( CLOUDED SULPHUR ):  55\n",
            "Validation size( CLOUDED SULPHUR ):  18\n",
            "Test size( CLOUDED SULPHUR ):  18\n",
            "Train size( COMMON BANDED AWL ):  52\n",
            "Validation size( COMMON BANDED AWL ):  17\n",
            "Test size( COMMON BANDED AWL ):  17\n",
            "Train size( COMMON WOOD-NYMPH ):  54\n",
            "Validation size( COMMON WOOD-NYMPH ):  18\n",
            "Test size( COMMON WOOD-NYMPH ):  18\n",
            "Train size( COPPER TAIL ):  56\n",
            "Validation size( COPPER TAIL ):  18\n",
            "Test size( COPPER TAIL ):  18\n",
            "Train size( CRECENT ):  58\n",
            "Validation size( CRECENT ):  19\n",
            "Test size( CRECENT ):  19\n",
            "Train size( CRIMSON PATCH ):  43\n",
            "Validation size( CRIMSON PATCH ):  14\n",
            "Test size( CRIMSON PATCH ):  14\n",
            "Train size( DANAID EGGFLY ):  56\n",
            "Validation size( DANAID EGGFLY ):  18\n",
            "Test size( DANAID EGGFLY ):  18\n",
            "Train size( EASTERN COMA ):  55\n",
            "Validation size( EASTERN COMA ):  18\n",
            "Test size( EASTERN COMA ):  18\n",
            "Train size( EASTERN DAPPLE WHITE ):  55\n",
            "Validation size( EASTERN DAPPLE WHITE ):  18\n",
            "Test size( EASTERN DAPPLE WHITE ):  18\n",
            "Train size( EASTERN PINE ELFIN ):  57\n",
            "Validation size( EASTERN PINE ELFIN ):  19\n",
            "Test size( EASTERN PINE ELFIN ):  19\n",
            "Train size( ELBOWED PIERROT ):  49\n",
            "Validation size( ELBOWED PIERROT ):  16\n",
            "Test size( ELBOWED PIERROT ):  16\n",
            "Train size( GOLD BANDED ):  43\n",
            "Validation size( GOLD BANDED ):  14\n",
            "Test size( GOLD BANDED ):  14\n",
            "Train size( GREAT EGGFLY ):  46\n",
            "Validation size( GREAT EGGFLY ):  15\n",
            "Test size( GREAT EGGFLY ):  15\n",
            "Train size( GREAT JAY ):  56\n",
            "Validation size( GREAT JAY ):  18\n",
            "Test size( GREAT JAY ):  18\n",
            "Train size( GREEN CELLED CATTLEHEART ):  52\n",
            "Validation size( GREEN CELLED CATTLEHEART ):  17\n",
            "Test size( GREEN CELLED CATTLEHEART ):  17\n",
            "Train size( GREY HAIRSTREAK ):  51\n",
            "Validation size( GREY HAIRSTREAK ):  17\n",
            "Test size( GREY HAIRSTREAK ):  17\n",
            "Train size( INDRA SWALLOW ):  48\n",
            "Validation size( INDRA SWALLOW ):  16\n",
            "Test size( INDRA SWALLOW ):  16\n",
            "Train size( IPHICLUS SISTER ):  57\n",
            "Validation size( IPHICLUS SISTER ):  19\n",
            "Test size( IPHICLUS SISTER ):  19\n",
            "Train size( JULIA ):  48\n",
            "Validation size( JULIA ):  16\n",
            "Test size( JULIA ):  16\n",
            "Train size( LARGE MARBLE ):  48\n",
            "Validation size( LARGE MARBLE ):  16\n",
            "Test size( LARGE MARBLE ):  16\n",
            "Train size( MALACHITE ):  43\n",
            "Validation size( MALACHITE ):  14\n",
            "Test size( MALACHITE ):  14\n",
            "Train size( MANGROVE SKIPPER ):  52\n",
            "Validation size( MANGROVE SKIPPER ):  17\n",
            "Test size( MANGROVE SKIPPER ):  17\n",
            "Train size( MESTRA ):  51\n",
            "Validation size( MESTRA ):  17\n",
            "Test size( MESTRA ):  17\n",
            "Train size( METALMARK ):  45\n",
            "Validation size( METALMARK ):  15\n",
            "Test size( METALMARK ):  15\n",
            "Train size( MILBERTS TORTOISESHELL ):  57\n",
            "Validation size( MILBERTS TORTOISESHELL ):  19\n",
            "Test size( MILBERTS TORTOISESHELL ):  19\n",
            "Train size( MONARCH ):  54\n",
            "Validation size( MONARCH ):  18\n",
            "Test size( MONARCH ):  18\n",
            "Train size( MOURNING CLOAK ):  78\n",
            "Validation size( MOURNING CLOAK ):  26\n",
            "Test size( MOURNING CLOAK ):  26\n",
            "Train size( ORANGE OAKLEAF ):  52\n",
            "Validation size( ORANGE OAKLEAF ):  17\n",
            "Test size( ORANGE OAKLEAF ):  17\n",
            "Train size( ORANGE TIP ):  57\n",
            "Validation size( ORANGE TIP ):  19\n",
            "Test size( ORANGE TIP ):  19\n",
            "Train size( ORCHARD SWALLOW ):  45\n",
            "Validation size( ORCHARD SWALLOW ):  15\n",
            "Test size( ORCHARD SWALLOW ):  15\n",
            "Train size( PAINTED LADY ):  46\n",
            "Validation size( PAINTED LADY ):  15\n",
            "Test size( PAINTED LADY ):  15\n",
            "Train size( PAPER KITE ):  54\n",
            "Validation size( PAPER KITE ):  18\n",
            "Test size( PAPER KITE ):  18\n",
            "Train size( PEACOCK ):  50\n",
            "Validation size( PEACOCK ):  16\n",
            "Test size( PEACOCK ):  16\n",
            "Train size( PINE WHITE ):  51\n",
            "Validation size( PINE WHITE ):  17\n",
            "Test size( PINE WHITE ):  17\n",
            "Train size( PIPEVINE SWALLOW ):  50\n",
            "Validation size( PIPEVINE SWALLOW ):  16\n",
            "Test size( PIPEVINE SWALLOW ):  16\n",
            "Train size( POPINJAY ):  51\n",
            "Validation size( POPINJAY ):  17\n",
            "Test size( POPINJAY ):  17\n",
            "Train size( PURPLE HAIRSTREAK ):  47\n",
            "Validation size( PURPLE HAIRSTREAK ):  15\n",
            "Test size( PURPLE HAIRSTREAK ):  15\n",
            "Train size( PURPLISH COPPER ):  55\n",
            "Validation size( PURPLISH COPPER ):  18\n",
            "Test size( PURPLISH COPPER ):  18\n",
            "Train size( QUESTION MARK ):  46\n",
            "Validation size( QUESTION MARK ):  15\n",
            "Test size( QUESTION MARK ):  15\n",
            "Train size( RED ADMIRAL ):  49\n",
            "Validation size( RED ADMIRAL ):  16\n",
            "Test size( RED ADMIRAL ):  16\n",
            "Train size( RED CRACKER ):  57\n",
            "Validation size( RED CRACKER ):  19\n",
            "Test size( RED CRACKER ):  19\n",
            "Train size( RED POSTMAN ):  53\n",
            "Validation size( RED POSTMAN ):  17\n",
            "Test size( RED POSTMAN ):  17\n",
            "Train size( RED SPOTTED PURPLE ):  51\n",
            "Validation size( RED SPOTTED PURPLE ):  17\n",
            "Test size( RED SPOTTED PURPLE ):  17\n",
            "Train size( SCARCE SWALLOW ):  58\n",
            "Validation size( SCARCE SWALLOW ):  19\n",
            "Test size( SCARCE SWALLOW ):  19\n",
            "Train size( SILVER SPOT SKIPPER ):  49\n",
            "Validation size( SILVER SPOT SKIPPER ):  16\n",
            "Test size( SILVER SPOT SKIPPER ):  16\n",
            "Train size( SLEEPY ORANGE ):  64\n",
            "Validation size( SLEEPY ORANGE ):  21\n",
            "Test size( SLEEPY ORANGE ):  21\n",
            "Train size( SOOTYWING ):  54\n",
            "Validation size( SOOTYWING ):  18\n",
            "Test size( SOOTYWING ):  18\n",
            "Train size( SOUTHERN DOGFACE ):  52\n",
            "Validation size( SOUTHERN DOGFACE ):  17\n",
            "Test size( SOUTHERN DOGFACE ):  17\n",
            "Train size( STRAITED QUEEN ):  52\n",
            "Validation size( STRAITED QUEEN ):  17\n",
            "Test size( STRAITED QUEEN ):  17\n",
            "Train size( TROPICAL LEAFWING ):  49\n",
            "Validation size( TROPICAL LEAFWING ):  16\n",
            "Test size( TROPICAL LEAFWING ):  16\n",
            "Train size( TWO BARRED FLASHER ):  45\n",
            "Validation size( TWO BARRED FLASHER ):  15\n",
            "Test size( TWO BARRED FLASHER ):  15\n",
            "Train size( ULYSES ):  50\n",
            "Validation size( ULYSES ):  16\n",
            "Test size( ULYSES ):  16\n",
            "Train size( VICEROY ):  48\n",
            "Validation size( VICEROY ):  16\n",
            "Test size( VICEROY ):  16\n",
            "Train size( WOOD SATYR ):  42\n",
            "Validation size( WOOD SATYR ):  14\n",
            "Test size( WOOD SATYR ):  14\n",
            "Train size( YELLOW SWALLOW TAIL ):  45\n",
            "Validation size( YELLOW SWALLOW TAIL ):  15\n",
            "Test size( YELLOW SWALLOW TAIL ):  15\n",
            "Train size( ZEBRA LONG WING ):  45\n",
            "Validation size( ZEBRA LONG WING ):  15\n",
            "Test size( ZEBRA LONG WING ):  15\n"
          ]
        }
      ],
      "source": [
        "for cls in classes_list:\n",
        "    path = os.path.join(original_dataset_dir, cls)\n",
        "    fnames = os.listdir(path)\n",
        "\n",
        "    train_size = math.floor(len(fnames) * 0.6)\n",
        "    validation_size = math.floor(len(fnames) * 0.2)\n",
        "    test_size = math.floor(len(fnames) * 0.2)\n",
        "\n",
        "    train_fnames = fnames[:train_size]\n",
        "    print(\"Train size(\",cls,\"): \", len(train_fnames))\n",
        "    for fname in train_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(train_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "    print(\"Validation size(\",cls,\"): \", len(validation_fnames))\n",
        "    for fname in validation_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    test_fnames = fnames[(train_size+validation_size):(validation_size + train_size +test_size)]\n",
        "\n",
        "    print(\"Test size(\",cls,\"): \", len(test_fnames))\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VZx2QslydI5r"
      },
      "outputs": [],
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "BATCH_SIZE = 256\n",
        "EPOCH = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz-rQx45dI5r",
        "outputId": "86e22443-1a35-4377-be58-a75a878a0374"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([transforms.Resize([64,64]),\n",
        "        transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomCrop(52), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),\n",
        "\n",
        "    'val': transforms.Compose([transforms.Resize([64,64]),\n",
        "        transforms.RandomCrop(52), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "}\n",
        "\n",
        "\n",
        "data_dir = './splitted'\n",
        "image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iej62b5dI5r",
        "outputId": "6b192d8c-e960-4612-da01-d5c9744c3d59"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_ftrs, 75)\n",
        "resnet = resnet.to('cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.001)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tD1pGqOvdI5s"
      },
      "outputs": [],
      "source": [
        "ct = 0\n",
        "for child in resnet.children():\n",
        "    ct += 1\n",
        "    if ct < 6:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tpA5h73bdI5s"
      },
      "outputs": [],
      "source": [
        "def train_resnet(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-------------- epoch {} ----------------'.format(epoch+1))\n",
        "        since = time.time()\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss/dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qubiD2WdI5t",
        "outputId": "337edd6e-1661-4064-b716-fd65d83d5a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------- epoch 1 ----------------\n",
            "train Loss: 0.1365 Acc: 0.9556\n",
            "val Loss: 0.5822 Acc: 0.8532\n",
            "Completed in 1m 47s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 0.1296 Acc: 0.9571\n",
            "val Loss: 0.5827 Acc: 0.8501\n",
            "Completed in 1m 44s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 0.1283 Acc: 0.9605\n",
            "val Loss: 0.5864 Acc: 0.8446\n",
            "Completed in 1m 45s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 0.1266 Acc: 0.9644\n",
            "val Loss: 0.5832 Acc: 0.8493\n",
            "Completed in 1m 48s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.1217 Acc: 0.9620\n",
            "val Loss: 0.5976 Acc: 0.8493\n",
            "Completed in 1m 46s\n",
            "-------------- epoch 6 ----------------\n",
            "train Loss: 0.1176 Acc: 0.9623\n",
            "val Loss: 0.5747 Acc: 0.8493\n",
            "Completed in 1m 49s\n",
            "-------------- epoch 7 ----------------\n",
            "train Loss: 0.1176 Acc: 0.9620\n",
            "val Loss: 0.5744 Acc: 0.8579\n",
            "Completed in 1m 43s\n",
            "-------------- epoch 8 ----------------\n",
            "train Loss: 0.1182 Acc: 0.9623\n",
            "val Loss: 0.5688 Acc: 0.8532\n",
            "Completed in 5m 13s\n",
            "-------------- epoch 9 ----------------\n",
            "train Loss: 0.1224 Acc: 0.9594\n",
            "val Loss: 0.5819 Acc: 0.8462\n",
            "Completed in 1m 47s\n",
            "-------------- epoch 10 ----------------\n",
            "train Loss: 0.1209 Acc: 0.9623\n",
            "val Loss: 0.5690 Acc: 0.8493\n",
            "Completed in 1m 48s\n",
            "Best val Acc: 0.857928\n"
          ]
        }
      ],
      "source": [
        "model_resnet50 = train_resnet(resnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10)\n",
        "\n",
        "torch.save(model_resnet50, 'resnet50.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6OGIaDPjiURm"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "\n",
        "            test_loss += F.cross_entropy(output,target, reduction='sum').item()\n",
        "\n",
        "\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8WgP0fmHg26Y"
      },
      "outputs": [],
      "source": [
        "transform_resNet = transforms.Compose([\n",
        "        transforms.Resize([64,64]),\n",
        "        transforms.RandomCrop(52),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_resNet = ImageFolder(root='./splitted/test', transform=transform_resNet)\n",
        "test_loader_resNet = torch.utils.data.DataLoader(test_resNet, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMiiqxJaiBQ8",
        "outputId": "41d991db-c53e-4f6f-c3a5-ba94e44e1288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet test acc:   86.65620094191523\n"
          ]
        }
      ],
      "source": [
        "resnet50=torch.load('resnet50.pt')\n",
        "resnet50.eval()\n",
        "test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n",
        "\n",
        "print('ResNet test acc:  ', test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
